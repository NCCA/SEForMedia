{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In the previous examples we have loaded the data from source and processed it ourselves. This helps us to get a deeper understanding of how the whole process works, and how we would go about training our own models. \n",
    "\n",
    "It is however, quite common to download datasets directly using the [`datasets`](https://pytorch.org/vision/stable/datasets.html#) library. This is a library that provides a simple way to download and load datasets for processing, it also includes many common datasets that are used in the research community and can be used to extend existing models or to train new models.\n",
    "\n",
    "In this example we will show how this works be using same process we used for the manual MNIST dataset, but this time we will use the `datasets` library to download the data for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import struct\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Visualization tools\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import Utils\n",
    "\n",
    "device = Utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will attempt to download the data into the /transfer folder if in the labs, else we will place it locally. In this case we will put it into a folder called mnist_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset location: ./mnist_data/\n"
     ]
    }
   ],
   "source": [
    "DATASET_LOCATION = \"\"\n",
    "if Utils.in_lab():\n",
    "    DATASET_LOCATION = \"/transfer/mnist_data/\"\n",
    "else:\n",
    "    DATASET_LOCATION = \"./mnist_data/\"\n",
    "\n",
    "print(f\"Dataset location: {DATASET_LOCATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now use the dataloaders to download the datasets to the above location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(DATASET_LOCATION, train=True, download=True)\n",
    "valid_set = torchvision.datasets.MNIST(DATASET_LOCATION, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the data is downloaded to the location specified and the data is loaded in the same way as before. However the loader returns a class called `torch.utils.data.DataLoader` which is a class that provides an iterator over the dataset. This is useful as it allows us to iterate over the dataset in a for loop, and also provides a way to shuffle the data and load it in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./mnist_data/\n",
      "    Split: Train\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./mnist_data/\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "print(type(train_set))\n",
    "print(train_set)\n",
    "\n",
    "print(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'> <class 'int'> (28, 28) 5\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVR4AWIY1IBZSEiormO91LL/3+tBDmUBESAsx2ZlIxAMYj2ZFPj54kEQixFEMDAwGO7lh7L+JX1lePb+JpQHBkK3/4LAsW3fP4L5qETAnOy/f89yM2jPQhWHAD7GWX+jIEwYyQRjMHz6/5EhBcGFi0MB976/blAmFkr548MFOTD3Y8gHfvj7t1wSQxgKdHf9/TtNGsrBoARi//zdjSEKBz///nSAcuBhC+HrhZiyMFw7BOGgkoCpT3n69+/fX9tQRcE8iaK7oOA96QfmoRDiTldBUscCMQNJaDU4Vg4HcKLoAHHM1zwC6frSyg3iITDYtYGBDAzXN//t+YAQpyULAEUXXoDz1Y8qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0, y_0 = train_set[0]\n",
    "print(type(x_0), type(y_0), x_0.size, y_0)\n",
    "x_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the data is stored as a PIL image and an integer. This is unlike the data we loaded in the previous demo which was the raw bytes. Basically the data loader class has done some pre-processing for us, and has loaded the data in a format that is ready to be used by the model. This is a common feature of the `datasets` library, and is one of the reasons why it is so popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\n",
    "\n",
    "The data loader class also allows us to apply transformations to the data. This is useful as it allows us to apply pre-processing to the data before it is loaded into the model. This can be useful for normalizing the data, or for augmenting the data to increase the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose(\n",
    "    [transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)]\n",
    ")\n",
    "train_set.transform = trans\n",
    "valid_set.transform = trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before we need to generate a full dataloader to batch our data. However is is now much simpler as we don't need to write our own class to do it as the data is already in the correct format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)\n",
    "type(valid_loader.dataset[0])\n",
    "print(valid_loader.dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "We will use the same model we used in the [previous notebook](ReadDigitsTraining.ipynb) to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "input_size = 28 * 28\n",
    "layers = [\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(input_size, 512),  # Input\n",
    "    nn.ReLU(),  # Activation for input\n",
    "    nn.Linear(512, 512),  # Hidden\n",
    "    nn.ReLU(),  # Activation for hidden\n",
    "    nn.Linear(512, n_classes),  # Output\n",
    "]\n",
    "model = nn.Sequential(*layers)\n",
    "model.to(device)\n",
    "next(model.parameters()).device\n",
    "if device == \"cuda\":\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Optimizer\n",
    "\n",
    "Next we can create our loss function and optimizer. We will use the same loss function and optimizer as before.\n",
    "\n",
    "We can also generate our loss calculation in a similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())\n",
    "train_N = len(train_loader.dataset)\n",
    "valid_N = len(valid_loader.dataset)\n",
    "\n",
    "\n",
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    # put model into training mode\n",
    "    model.train()\n",
    "    # send data to the device\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print(\"Train - Loss: {:.4f} Accuracy: {:.4f}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    # put model into evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    print(\"Valid - Loss: {:.4f} Accuracy: {:.4f}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train - Loss: 384.6146 Accuracy: 0.9379\n",
      "Valid - Loss: 34.1882 Accuracy: 0.9649\n",
      "Epoch: 1\n",
      "Train - Loss: 156.4169 Accuracy: 0.9743\n",
      "Valid - Loss: 24.3584 Accuracy: 0.9743\n",
      "Epoch: 2\n",
      "Train - Loss: 109.7646 Accuracy: 0.9819\n",
      "Valid - Loss: 28.0781 Accuracy: 0.9724\n",
      "Epoch: 3\n",
      "Train - Loss: 82.0198 Accuracy: 0.9865\n",
      "Valid - Loss: 30.7555 Accuracy: 0.9720\n",
      "Epoch: 4\n",
      "Train - Loss: 67.8742 Accuracy: 0.9883\n",
      "Valid - Loss: 21.5227 Accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "prediction = model(train_set[0][0].to(device).unsqueeze(0))\n",
    "print(prediction.argmax(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "As you can see the processes are very similar, just the model loading and prep are a little simpler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
