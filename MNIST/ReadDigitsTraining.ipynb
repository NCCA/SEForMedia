{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits\n",
    "\n",
    "In this notebook we are going to train a neural network to recognize handwritten digits. This is the  \"Hello World\" of deep learning: training a deep learning model to correctly classify hand-written digits.\n",
    "\n",
    "In the previous [notebook](TheMNISTDataSet.ipynb) we downloaded the MNIST dataset, which is a dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.  We will re-use this data (downloaded either to your local hard drive or /transfer) to train a neural network to recognize the digits.\n",
    "\n",
    "We will start by importing the necessary libraries, including our Utils module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utils.in_lab()=False\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import struct\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "# Visualization tools\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import Utils\n",
    "\n",
    "print(f\"{Utils.in_lab()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Support\n",
    "\n",
    "In this notebook we will use the GPU to train our model, we can use the function from our Utils module to check if the GPU is available and set this as the device to use for our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = Utils.get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification\n",
    "\n",
    "The approach we are going to take with this example is to load a set of know images and their labels, and train a neural network to learn the relationship between the images and their labels. \n",
    "\n",
    "We will use a neural network and a trial and error system to begin to recognize the patterns in the images. The images are small (28x28 pixels) and the neural network will learn to recognize the patterns in the images that are associated with the digits.\n",
    "\n",
    "We have a set of 60,000 images to train the network and a separate set of 10,000 images to test the network and on each step of the training process we will check the accuracy of the network on the test set.\n",
    "\n",
    "In the previous notebook we created two functions for loading the data and labels so we will use these functions to load the data and labels for the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_labels(filename: str) -> np.ndarray:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        if len(labels) != num:\n",
    "            raise ValueError(f\"Expected {num} labels, but got {len(labels)}\")\n",
    "    return labels\n",
    "\n",
    "def load_mnist_images(filename: str) -> np.ndarray:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)\n",
    "        if len(images) != num:\n",
    "            raise ValueError(f\"Expected {num} images, but got {len(images)}\")\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n",
      "5 7\n"
     ]
    }
   ],
   "source": [
    "DATASET_LOCATION = \"\"\n",
    "if Utils.in_lab():\n",
    "    DATASET_LOCATION = \"/transfer/MNIST/\"\n",
    "else:\n",
    "    DATASET_LOCATION = \"./MNIST/\"\n",
    "\n",
    "train_labels = load_mnist_labels(DATASET_LOCATION + \"train-labels-idx1-ubyte\")\n",
    "test_labels = load_mnist_labels(DATASET_LOCATION + \"t10k-labels-idx1-ubyte\")\n",
    "\n",
    "print(len(train_labels), len(test_labels))\n",
    "print(train_labels[0], test_labels[0])\n",
    "\n",
    "# We can now load the images from both the datasets.\n",
    "train_images = load_mnist_images(DATASET_LOCATION + \"train-images-idx3-ubyte\")\n",
    "test_images = load_mnist_images(DATASET_LOCATION + \"t10k-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the images we can define a simple function to display the images. We will use the matplotlib library to display the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "def display_image(image: np.array, label: str) -> None:\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.title(f\"Label : {label}\")\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# We can now display the first image from the training dataset.\n",
    "\n",
    "display_image(train_images[0], train_labels[0])\n",
    "print(type(train_images[0]))\n",
    "print(train_images[0].shape)\n",
    "print(train_images[0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the data it is stored in a numpy array of 28,28 and a single unsigned char data type. We need to transform this data into the correct type for machine learning. In particular we need to convert the data into a Tensor of type float32, then we need to batch the data into a DataLoader.\n",
    "\n",
    "We can use the torchvision library to transform our data as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.float32\n",
      "tensor(0.) tensor(1.)\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trans = transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)])\n",
    "tensor=trans(train_images[0])\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.min(), tensor.max())\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the data for this tensor is processed on the CPU, we can convert "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
